{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a9b7c88",
   "metadata": {},
   "source": [
    "1. Importações e definições de variáveis de ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b0bd2dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETL RAW -> SILVER | SINISTROS PRF\n"
     ]
    }
   ],
   "source": [
    "# 1. Configuração e Importações\n",
    "\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_batch\n",
    "import os\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", 80)\n",
    "\n",
    "print(\"ETL RAW -> SILVER | SINISTROS PRF\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10648602",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fd70f093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos encontrados em raw: 2\n",
      " - /home/matheus-brant/Desktop/referencia/SBD2-Grupo-19-PRF/data_layer/raw/dados_brutos_2024.csv\n",
      " - /home/matheus-brant/Desktop/referencia/SBD2-Grupo-19-PRF/data_layer/raw/dados_brutos_2025.csv\n"
     ]
    }
   ],
   "source": [
    "# 1.1 Caminhos (Raw e Silver)\n",
    "\n",
    "BASE_PATH = Path(os.getcwd()).parent.parent\n",
    "DATA_LAYER_RAW_PATH = BASE_PATH / \"data_layer\" / \"raw\"\n",
    "DATA_LAYER_SILVER_PATH = BASE_PATH / \"data_layer\" / \"silver\" / \"data\"\n",
    "\n",
    "DATA_LAYER_SILVER_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Procura automaticamente CSVs de 2024 e 2025 na pasta raw\n",
    "RAW_FILES = sorted([p for p in DATA_LAYER_RAW_PATH.iterdir() if p.suffix.lower() == \".csv\"])\n",
    "\n",
    "print(f\"Arquivos encontrados em raw: {len(RAW_FILES)}\")\n",
    "for p in RAW_FILES:\n",
    "    print(\" -\", p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e628c107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB host: localhost\n",
      "DB port: 5432\n",
      "DB name: prf\n"
     ]
    }
   ],
   "source": [
    "# 1.2 Banco (env)\n",
    "\n",
    "load_dotenv(BASE_PATH / \".env\")\n",
    "\n",
    "DB_CONFIG = {\n",
    "    \"host\": os.getenv(\"DB_HOST\"),\n",
    "    \"port\": os.getenv(\"DB_PORT\"),\n",
    "    \"database\": os.getenv(\"POSTGRES_DB\"),\n",
    "    \"user\": os.getenv(\"POSTGRES_USER\"),\n",
    "    \"password\": os.getenv(\"POSTGRES_PASSWORD\"),\n",
    "}\n",
    "\n",
    "print(\"DB host:\", DB_CONFIG[\"host\"])\n",
    "print(\"DB port:\", DB_CONFIG[\"port\"])\n",
    "print(\"DB name:\", DB_CONFIG[\"database\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63ff0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Normalização de texto (tirar espaços, padronizar nulos e evitar lixo)\n",
    "\n",
    "NULL_LIKE = {\n",
    "    \"\", \" \", \"null\", \"none\", \"nan\", \"na\", \"n/a\", \"(null)\", \"NoneType\", \"NaN\", \"NULL\", \"N/A\"\n",
    "}\n",
    "\n",
    "def normalize_text_series(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    - strip + colapsa espaços\n",
    "    - troca valores tipo 'null', 'nan', '' por <NA>\n",
    "    - mantém como string (nullable)\n",
    "    \"\"\"\n",
    "    s = s.astype(\"string\")\n",
    "\n",
    "    # normaliza unicode e remove espaços extras\n",
    "    s = s.map(lambda x: unicodedata.normalize(\"NFKC\", x) if pd.notna(x) else x)\n",
    "    s = s.str.strip()\n",
    "    s = s.str.replace(r\"\\s+\", \" \", regex=True)\n",
    "\n",
    "    # padroniza nulos\n",
    "    s_lower = s.str.lower()\n",
    "    s = s.mask(s_lower.isin(NULL_LIKE), pd.NA)\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "def safe_to_int(s: pd.Series) -> pd.Series:\n",
    "    return pd.to_numeric(s, errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "\n",
    "def safe_to_float(s: pd.Series) -> pd.Series:\n",
    "    # aceita vírgula ou ponto\n",
    "    s = s.astype(\"string\").str.replace(\",\", \".\", regex=False)\n",
    "    return pd.to_numeric(s, errors=\"coerce\").astype(\"Float64\")\n",
    "\n",
    "def validate_coordinates(lat: pd.Series, lon: pd.Series) -> tuple[pd.Series, pd.Series]:\n",
    "    \n",
    "    lat_valid = lat.where((lat.isna()) | ((lat >= -90) & (lat <= 90)), pd.NA)\n",
    "    lon_valid = lon.where((lon.isna()) | ((lon >= -180) & (lon <= 180)), pd.NA)\n",
    "    return lat_valid.astype(\"Float64\"), lon_valid.astype(\"Float64\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "877943a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Parse de horário (aceita HH:MM:SS e HH:MM)\n",
    "\n",
    "def parse_time_series(s: pd.Series) -> pd.Series:\n",
    "    s = s.astype(\"string\")\n",
    "    s = normalize_text_series(s)\n",
    "\n",
    "    t1 = pd.to_datetime(s, format=\"%H:%M:%S\", errors=\"coerce\")\n",
    "    t2 = pd.to_datetime(s, format=\"%H:%M\", errors=\"coerce\")\n",
    "\n",
    "    t = t1.fillna(t2)\n",
    "    return t.dt.time  # python datetime.time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2f2ad581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Dia da semana -> número (Seg=0 ... Dom=6)\n",
    "\n",
    "DIA_SEMANA_MAP = {\n",
    "    \"segunda-feira\": 0,\n",
    "    \"terca-feira\": 1,\n",
    "    \"terça-feira\": 1,\n",
    "    \"quarta-feira\": 2,\n",
    "    \"quinta-feira\": 3,\n",
    "    \"sexta-feira\": 4,\n",
    "    \"sabado\": 5,\n",
    "    \"sábado\": 5,\n",
    "    \"domingo\": 6,\n",
    "}\n",
    "\n",
    "def normalize_day_name(x: str) -> str:\n",
    "    if x is None or pd.isna(x):\n",
    "        return None\n",
    "    x = unicodedata.normalize(\"NFKD\", str(x)).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    x = x.strip().lower()\n",
    "    return x\n",
    "\n",
    "def map_dia_semana_num(s: pd.Series) -> pd.Series:\n",
    "    s = normalize_text_series(s)\n",
    "    s = s.map(normalize_day_name)\n",
    "    return s.map(DIA_SEMANA_MAP).astype(\"Int64\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5c542ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 Padronizar sexo -> masculino | feminino | ignorado\n",
    "\n",
    "def padronizar_sexo(s: pd.Series) -> pd.Series:\n",
    "    s = normalize_text_series(s)\n",
    "\n",
    "    def _map(x):\n",
    "        if x is None or pd.isna(x):\n",
    "            return pd.NA\n",
    "        v = str(x).strip().lower()\n",
    "        v = unicodedata.normalize(\"NFKD\", v).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "\n",
    "        if v in {\"m\", \"masc\", \"masculino\"}:\n",
    "            return \"masculino\"\n",
    "        if v in {\"f\", \"fem\", \"feminino\"}:\n",
    "            return \"feminino\"\n",
    "\n",
    "        # tudo que não der pra confiar cai em ignorado\n",
    "        if v in {\"ignorado\", \"nao informado\", \"nao-informado\", \"não informado\", \"não-informado\", \"0\"}:\n",
    "            return \"ignorado\"\n",
    "\n",
    "        return \"ignorado\"\n",
    "\n",
    "    out = s.map(_map).astype(\"string\")\n",
    "    return out\n",
    "\n",
    "# 2.X Padronizar estado_fisico -> ileso | leve | grave | obito | ignorado\n",
    "\n",
    "def padronizar_estado_fisico(s: pd.Series) -> pd.Series:\n",
    "    s = normalize_text_series(s)\n",
    "\n",
    "    def _map(x):\n",
    "        if x is None or pd.isna(x):\n",
    "            return \"ignorado\"\n",
    "\n",
    "        v = str(x).strip().lower()\n",
    "        # remove acentos pra facilitar comparação\n",
    "        v = unicodedata.normalize(\"NFKD\", v).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "\n",
    "        # casos comuns\n",
    "        if \"obito\" in v or \"morto\" in v:\n",
    "            return \"obito\"\n",
    "\n",
    "        if \"grave\" in v:\n",
    "            return \"grave\"\n",
    "\n",
    "        # \"lesoes leves\", \"lesao leve\", \"leve\"\n",
    "        if \"leve\" in v:\n",
    "            return \"leve\"\n",
    "\n",
    "        if \"ileso\" in v or \"sem ferimentos\" in v:\n",
    "            return \"ileso\"\n",
    "\n",
    "        # tudo que não for confiável vai pra ignorado\n",
    "        if v in {\"ignorado\", \"nao informado\", \"nao-informado\", \"0\"}:\n",
    "            return \"ignorado\"\n",
    "\n",
    "        return \"ignorado\"\n",
    "\n",
    "    return s.map(_map).astype(\"string\")\n",
    "\n",
    "# 2.X Padronizar uso_solo -> caracteristicas_via (urbano | rural | ignorado)\n",
    "def padronizar_uso_solo(s: pd.Series) -> pd.Series:\n",
    "    s = normalize_text_series(s)\n",
    "\n",
    "    def _map(x):\n",
    "        if x is None or pd.isna(x):\n",
    "            return \"ignorado\"\n",
    "\n",
    "        v = str(x).strip().lower()\n",
    "        v = unicodedata.normalize(\"NFKD\", v).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "\n",
    "        if v == \"sim\":\n",
    "            return \"urbano\"\n",
    "        if v == \"nao\":\n",
    "            return \"rural\"\n",
    "\n",
    "        return \"ignorado\"\n",
    "\n",
    "    return s.map(_map).astype(\"string\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "46c12f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5 Faixa etária (idade_condutor / idade) -> bins 0-9 ... 100+\n",
    "\n",
    "def faixa_etaria_bins(idade_s: pd.Series) -> pd.Series:\n",
    "    idade = pd.to_numeric(idade_s, errors=\"coerce\")\n",
    "\n",
    "    # regra simples: 0 ou negativo = desconhecido\n",
    "    idade = idade.mask((idade <= 0) | (idade > 120), np.nan)\n",
    "\n",
    "    bins = [-0.1, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99, 10_000]\n",
    "    labels = [\"0-9\",\"10-19\",\"20-29\",\"30-39\",\"40-49\",\"50-59\",\"60-69\",\"70-79\",\"80-89\",\"90-99\",\"100+\"]\n",
    "\n",
    "    faixa = pd.cut(idade, bins=bins, labels=labels)\n",
    "    return faixa.astype(\"string\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b4b1f6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.6 Faixa de idade do veículo (ano_fabricacao_veiculo -> idade do veículo -> bins)\n",
    "\n",
    "def faixa_idade_veiculo_bins(ano_fab_s: pd.Series, ano_ref_s: pd.Series) -> pd.Series:\n",
    "    ano_fab = pd.to_numeric(ano_fab_s, errors=\"coerce\")\n",
    "    ano_ref = pd.to_numeric(ano_ref_s, errors=\"coerce\")\n",
    "\n",
    "    idade_veic = ano_ref - ano_fab\n",
    "    idade_veic = idade_veic.mask((idade_veic < 0) | (idade_veic > 120), np.nan)\n",
    "\n",
    "    bins = [-0.1, 4, 9, 14, 19, 29, 120]\n",
    "    labels = [\"0-4\",\"5-9\",\"10-14\",\"15-19\",\"20-29\",\"30+\"]\n",
    "\n",
    "    faixa = pd.cut(idade_veic, bins=bins, labels=labels)\n",
    "    return faixa.astype(\"string\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c8f790f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Carregando dados Raw...\n",
      "Carregado: 372,148 linhas x 36 colunas\n",
      "Colunas: ['id', 'pesid', 'data_inversa', 'dia_semana', 'horario', 'uf', 'br', 'km', 'municipio', 'causa_acidente', 'tipo_acidente', 'classificacao_acidente', 'fase_dia', 'sentido_via', 'condicao_metereologica', 'tipo_pista', 'tracado_via', 'uso_solo', 'id_veiculo', 'tipo_veiculo', 'marca', 'ano_fabricacao_veiculo', 'tipo_envolvido', 'estado_fisico', 'idade', 'sexo', 'ilesos', 'feridos_leves', 'feridos_graves', 'mortos', 'latitude', 'longitude', 'regional', 'delegacia', 'uop', '__source_file']\n"
     ]
    }
   ],
   "source": [
    "def load_raw_csvs(csv_paths: list[Path]) -> pd.DataFrame:\n",
    "    dfs = []\n",
    "    for p in csv_paths:\n",
    "        df = pd.read_csv(\n",
    "            p,\n",
    "            sep=\";\",\n",
    "            encoding=\"ISO-8859-1\",\n",
    "            low_memory=False,\n",
    "            dtype=str,  # lê tudo como string para controlar conversões depois\n",
    "        )\n",
    "        df[\"__source_file\"] = p.name\n",
    "        dfs.append(df)\n",
    "\n",
    "    df_all = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
    "    return df_all\n",
    "\n",
    "\n",
    "print(\"\\nCarregando dados Raw...\")\n",
    "df_raw = load_raw_csvs(RAW_FILES)\n",
    "\n",
    "print(f\"Carregado: {df_raw.shape[0]:,} linhas x {df_raw.shape[1]:,} colunas\")\n",
    "print(\"Colunas:\", list(df_raw.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e737c0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INICIANDO TRANSFORM (RAW -> SILVER)\n",
      "Shape inicial: (372148, 36)\n",
      "1) Normalizando texto...\n",
      "2) Convertendo IDs...\n",
      "3) Convertendo data e horário...\n",
      "4) Criando data_hora...\n",
      "5) Convertendo latitude/longitude...\n",
      "6) Aplicando filtro ano_arquivo (2024/2025)...\n",
      "   Linhas removidas pelo filtro: 0\n",
      "7) Garantindo colunas do DDL...\n",
      "8) Removendo duplicatas por (sinistro_id, pessoa_id)...\n",
      "   Duplicatas removidas: 12,141\n",
      "Shape final (silver): (360007, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano_arquivo</th>\n",
       "      <th>sinistro_id</th>\n",
       "      <th>pessoa_id</th>\n",
       "      <th>veiculo_id</th>\n",
       "      <th>data_hora</th>\n",
       "      <th>dia_semana_num</th>\n",
       "      <th>uf</th>\n",
       "      <th>municipio</th>\n",
       "      <th>delegacia</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>causa_acidente</th>\n",
       "      <th>tipo_acidente</th>\n",
       "      <th>classificacao_acidente</th>\n",
       "      <th>fase_dia</th>\n",
       "      <th>sentido_via</th>\n",
       "      <th>condicao_meteorologica</th>\n",
       "      <th>tipo_pista</th>\n",
       "      <th>tracado_via</th>\n",
       "      <th>caracteristicas_via</th>\n",
       "      <th>tipo_envolvido</th>\n",
       "      <th>estado_fisico</th>\n",
       "      <th>faixa_etaria_condutor</th>\n",
       "      <th>sexo_condutor</th>\n",
       "      <th>tipo_veiculo</th>\n",
       "      <th>faixa_idade_veiculo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41640</th>\n",
       "      <td>2024</td>\n",
       "      <td>571772</td>\n",
       "      <td>1268971</td>\n",
       "      <td>1018215</td>\n",
       "      <td>2024-01-01 00:05:00</td>\n",
       "      <td>0</td>\n",
       "      <td>RJ</td>\n",
       "      <td>TANGUA</td>\n",
       "      <td>DEL02-RJ</td>\n",
       "      <td>-22.72936</td>\n",
       "      <td>-42.701125</td>\n",
       "      <td>Reação tardia ou ineficiente do condutor</td>\n",
       "      <td>Colisão com objeto</td>\n",
       "      <td>Com Vítimas Fatais</td>\n",
       "      <td>Plena Noite</td>\n",
       "      <td>Decrescente</td>\n",
       "      <td>Céu Claro</td>\n",
       "      <td>Dupla</td>\n",
       "      <td>Reta</td>\n",
       "      <td>urbano</td>\n",
       "      <td>Condutor</td>\n",
       "      <td>obito</td>\n",
       "      <td>20-29</td>\n",
       "      <td>masculino</td>\n",
       "      <td>Motocicleta</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41641</th>\n",
       "      <td>2024</td>\n",
       "      <td>571774</td>\n",
       "      <td>1268985</td>\n",
       "      <td>1018226</td>\n",
       "      <td>2024-01-01 00:05:00</td>\n",
       "      <td>0</td>\n",
       "      <td>GO</td>\n",
       "      <td>ANAPOLIS</td>\n",
       "      <td>DEL02-GO</td>\n",
       "      <td>-16.229185</td>\n",
       "      <td>-49.009797</td>\n",
       "      <td>Velocidade Incompatível</td>\n",
       "      <td>Colisão com objeto</td>\n",
       "      <td>Sem Vítimas</td>\n",
       "      <td>Plena Noite</td>\n",
       "      <td>Decrescente</td>\n",
       "      <td>Céu Claro</td>\n",
       "      <td>Dupla</td>\n",
       "      <td>Reta</td>\n",
       "      <td>rural</td>\n",
       "      <td>Condutor</td>\n",
       "      <td>ileso</td>\n",
       "      <td>30-39</td>\n",
       "      <td>feminino</td>\n",
       "      <td>Automóvel</td>\n",
       "      <td>15-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41642</th>\n",
       "      <td>2024</td>\n",
       "      <td>571777</td>\n",
       "      <td>1269020</td>\n",
       "      <td>1018251</td>\n",
       "      <td>2024-01-01 01:45:00</td>\n",
       "      <td>0</td>\n",
       "      <td>ES</td>\n",
       "      <td>SERRA</td>\n",
       "      <td>DEL02-ES</td>\n",
       "      <td>-20.172928</td>\n",
       "      <td>-40.267364</td>\n",
       "      <td>Reação tardia ou ineficiente do condutor</td>\n",
       "      <td>Colisão com objeto</td>\n",
       "      <td>Sem Vítimas</td>\n",
       "      <td>Plena Noite</td>\n",
       "      <td>Decrescente</td>\n",
       "      <td>Nublado</td>\n",
       "      <td>Múltipla</td>\n",
       "      <td>Interseção de Vias;Reta</td>\n",
       "      <td>urbano</td>\n",
       "      <td>Condutor</td>\n",
       "      <td>ileso</td>\n",
       "      <td>50-59</td>\n",
       "      <td>masculino</td>\n",
       "      <td>Caminhonete</td>\n",
       "      <td>15-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41643</th>\n",
       "      <td>2024</td>\n",
       "      <td>571778</td>\n",
       "      <td>1269028</td>\n",
       "      <td>1018261</td>\n",
       "      <td>2024-01-01 00:45:00</td>\n",
       "      <td>0</td>\n",
       "      <td>SC</td>\n",
       "      <td>PENHA</td>\n",
       "      <td>DEL03-SC</td>\n",
       "      <td>-26.83477</td>\n",
       "      <td>-48.706151</td>\n",
       "      <td>Acumulo de água sobre o pavimento</td>\n",
       "      <td>Saída de leito carroçável</td>\n",
       "      <td>Com Vítimas Feridas</td>\n",
       "      <td>Plena Noite</td>\n",
       "      <td>Crescente</td>\n",
       "      <td>Chuva</td>\n",
       "      <td>Dupla</td>\n",
       "      <td>Curva</td>\n",
       "      <td>rural</td>\n",
       "      <td>Condutor</td>\n",
       "      <td>ileso</td>\n",
       "      <td>50-59</td>\n",
       "      <td>masculino</td>\n",
       "      <td>Camioneta</td>\n",
       "      <td>10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41644</th>\n",
       "      <td>2024</td>\n",
       "      <td>571778</td>\n",
       "      <td>1269045</td>\n",
       "      <td>1018261</td>\n",
       "      <td>2024-01-01 00:45:00</td>\n",
       "      <td>0</td>\n",
       "      <td>SC</td>\n",
       "      <td>PENHA</td>\n",
       "      <td>DEL03-SC</td>\n",
       "      <td>-26.83477</td>\n",
       "      <td>-48.706151</td>\n",
       "      <td>Acumulo de água sobre o pavimento</td>\n",
       "      <td>Saída de leito carroçável</td>\n",
       "      <td>Com Vítimas Feridas</td>\n",
       "      <td>Plena Noite</td>\n",
       "      <td>Crescente</td>\n",
       "      <td>Chuva</td>\n",
       "      <td>Dupla</td>\n",
       "      <td>Curva</td>\n",
       "      <td>rural</td>\n",
       "      <td>Passageiro</td>\n",
       "      <td>leve</td>\n",
       "      <td>30-39</td>\n",
       "      <td>feminino</td>\n",
       "      <td>Camioneta</td>\n",
       "      <td>10-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ano_arquivo  sinistro_id  pessoa_id  veiculo_id           data_hora  \\\n",
       "41640         2024       571772    1268971     1018215 2024-01-01 00:05:00   \n",
       "41641         2024       571774    1268985     1018226 2024-01-01 00:05:00   \n",
       "41642         2024       571777    1269020     1018251 2024-01-01 01:45:00   \n",
       "41643         2024       571778    1269028     1018261 2024-01-01 00:45:00   \n",
       "41644         2024       571778    1269045     1018261 2024-01-01 00:45:00   \n",
       "\n",
       "       dia_semana_num  uf municipio delegacia   latitude  longitude  \\\n",
       "41640               0  RJ    TANGUA  DEL02-RJ  -22.72936 -42.701125   \n",
       "41641               0  GO  ANAPOLIS  DEL02-GO -16.229185 -49.009797   \n",
       "41642               0  ES     SERRA  DEL02-ES -20.172928 -40.267364   \n",
       "41643               0  SC     PENHA  DEL03-SC  -26.83477 -48.706151   \n",
       "41644               0  SC     PENHA  DEL03-SC  -26.83477 -48.706151   \n",
       "\n",
       "                                 causa_acidente              tipo_acidente  \\\n",
       "41640  Reação tardia ou ineficiente do condutor         Colisão com objeto   \n",
       "41641                   Velocidade Incompatível         Colisão com objeto   \n",
       "41642  Reação tardia ou ineficiente do condutor         Colisão com objeto   \n",
       "41643         Acumulo de água sobre o pavimento  Saída de leito carroçável   \n",
       "41644         Acumulo de água sobre o pavimento  Saída de leito carroçável   \n",
       "\n",
       "      classificacao_acidente     fase_dia  sentido_via condicao_meteorologica  \\\n",
       "41640     Com Vítimas Fatais  Plena Noite  Decrescente              Céu Claro   \n",
       "41641            Sem Vítimas  Plena Noite  Decrescente              Céu Claro   \n",
       "41642            Sem Vítimas  Plena Noite  Decrescente                Nublado   \n",
       "41643    Com Vítimas Feridas  Plena Noite    Crescente                  Chuva   \n",
       "41644    Com Vítimas Feridas  Plena Noite    Crescente                  Chuva   \n",
       "\n",
       "      tipo_pista              tracado_via caracteristicas_via tipo_envolvido  \\\n",
       "41640      Dupla                     Reta              urbano       Condutor   \n",
       "41641      Dupla                     Reta               rural       Condutor   \n",
       "41642   Múltipla  Interseção de Vias;Reta              urbano       Condutor   \n",
       "41643      Dupla                    Curva               rural       Condutor   \n",
       "41644      Dupla                    Curva               rural     Passageiro   \n",
       "\n",
       "      estado_fisico faixa_etaria_condutor sexo_condutor tipo_veiculo  \\\n",
       "41640         obito                 20-29     masculino  Motocicleta   \n",
       "41641         ileso                 30-39      feminino    Automóvel   \n",
       "41642         ileso                 50-59     masculino  Caminhonete   \n",
       "41643         ileso                 50-59     masculino    Camioneta   \n",
       "41644          leve                 30-39      feminino    Camioneta   \n",
       "\n",
       "      faixa_idade_veiculo  \n",
       "41640                 0-4  \n",
       "41641               15-19  \n",
       "41642               15-19  \n",
       "41643               10-14  \n",
       "41644               10-14  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.1 Pipeline principal\n",
    "\n",
    "DDL_COLUMNS = [\n",
    "    \"ano_arquivo\",\n",
    "    \"sinistro_id\",\n",
    "    \"pessoa_id\",\n",
    "    \"veiculo_id\",\n",
    "    \"data_hora\",\n",
    "    \"dia_semana_num\",\n",
    "    \"uf\",\n",
    "    \"municipio\",\n",
    "    \"delegacia\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"causa_acidente\",\n",
    "    \"tipo_acidente\",\n",
    "    \"classificacao_acidente\",\n",
    "    \"fase_dia\",\n",
    "    \"sentido_via\",\n",
    "    \"condicao_meteorologica\",\n",
    "    \"tipo_pista\",\n",
    "    \"tracado_via\",\n",
    "    \"caracteristicas_via\",\n",
    "    \"tipo_envolvido\",\n",
    "    \"estado_fisico\",\n",
    "    \"faixa_etaria_condutor\",\n",
    "    \"sexo_condutor\",\n",
    "    \"tipo_veiculo\",\n",
    "    \"faixa_idade_veiculo\",\n",
    "    # \"created_at\" -> no banco tem default NOW(), então não precisa vir no insert\n",
    "]\n",
    "\n",
    "\n",
    "def transformar_para_silver(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    print(\"\\nINICIANDO TRANSFORM (RAW -> SILVER)\")\n",
    "    print(f\"Shape inicial: {df.shape}\")\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1) Normalizar strings em todas as colunas\n",
    "    print(\"1) Normalizando texto...\")\n",
    "    for col in df.columns:\n",
    "        df[col] = normalize_text_series(df[col])\n",
    "\n",
    "    # 2) Corrigir nome de coluna (condicao_metereologica -> condicao_meteorologica)\n",
    "    if \"condicao_metereologica\" in df.columns:\n",
    "        df = df.rename(columns={\"condicao_metereologica\": \"condicao_meteorologica\"})\n",
    "\n",
    "    # 3) IDs (padrão do banco)\n",
    "    print(\"2) Convertendo IDs...\")\n",
    "    if \"id\" in df.columns:\n",
    "        df[\"sinistro_id\"] = safe_to_int(df[\"id\"])\n",
    "    else:\n",
    "        df[\"sinistro_id\"] = pd.NA\n",
    "\n",
    "    if \"pesid\" in df.columns:\n",
    "        df[\"pessoa_id\"] = safe_to_int(df[\"pesid\"])\n",
    "    else:\n",
    "        df[\"pessoa_id\"] = pd.NA\n",
    "\n",
    "    if \"id_veiculo\" in df.columns:\n",
    "        df[\"veiculo_id\"] = safe_to_int(df[\"id_veiculo\"])\n",
    "    else:\n",
    "        df[\"veiculo_id\"] = pd.NA\n",
    "\n",
    "    # 4) Data e hora\n",
    "    print(\"3) Convertendo data e horário...\")\n",
    "    df[\"data_inversa_dt\"] = pd.to_datetime(df.get(\"data_inversa\"), format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "    df[\"horario_time\"] = parse_time_series(df.get(\"horario\"))\n",
    "\n",
    "    # 5) data_hora (timestamp completo)\n",
    "    print(\"4) Criando data_hora...\")\n",
    "    df[\"ano_arquivo\"] = df[\"data_inversa_dt\"].dt.year.astype(\"Int64\")\n",
    "\n",
    "    # data_hora: if time is missing, use 00:00:00 (don't lose the row)\n",
    "    hora_txt = df[\"horario_time\"].astype(\"string\").fillna(\"00:00:00\")\n",
    "    df[\"data_hora\"] = pd.to_datetime(\n",
    "        df[\"data_inversa_dt\"].astype(\"string\") + \" \" + hora_txt,\n",
    "        errors=\"coerce\"\n",
    "        )\n",
    "\n",
    "    # 6) ano_arquivo (ano do sinistro)\n",
    "    df[\"ano_arquivo\"] = df[\"data_hora\"].dt.year.astype(\"Int64\")\n",
    "\n",
    "    # 7) dia_semana_num\n",
    "    df[\"dia_semana_num\"] = map_dia_semana_num(df.get(\"dia_semana\"))\n",
    "\n",
    "    # 8) Latitude / Longitude\n",
    "    print(\"5) Convertendo latitude/longitude...\")\n",
    "    df[\"latitude\"] = safe_to_float(df.get(\"latitude\"))\n",
    "    df[\"longitude\"] = safe_to_float(df.get(\"longitude\"))\n",
    "    df[\"latitude\"], df[\"longitude\"] = validate_coordinates(df[\"latitude\"], df[\"longitude\"])\n",
    "\n",
    "    # 9) caracteristicas_via (vem de uso_solo) -> urbano | rural | ignorado\n",
    "    df[\"caracteristicas_via\"] = padronizar_uso_solo(df.get(\"uso_solo\"))\n",
    "\n",
    "    # 10) sexo_condutor (vem de sexo)\n",
    "    df[\"sexo_condutor\"] = padronizar_sexo(df.get(\"sexo\"))\n",
    "\n",
    "    # 10.5) estado_fisico padronizado (vem de estado_fisico)\n",
    "    df[\"estado_fisico\"] = padronizar_estado_fisico(df.get(\"estado_fisico\"))\n",
    "\n",
    "    # 11) faixa_etaria_condutor (vem de idade_condutor / idade)\n",
    "    # no seu CSV está como \"idade\"\n",
    "    df[\"faixa_etaria_condutor\"] = faixa_etaria_bins(df.get(\"idade\"))\n",
    "\n",
    "    # 12) faixa_idade_veiculo (derivada de ano_fabricacao_veiculo)\n",
    "    df[\"faixa_idade_veiculo\"] = faixa_idade_veiculo_bins(df.get(\"ano_fabricacao_veiculo\"), df[\"ano_arquivo\"])\n",
    "\n",
    "    # 13) UF em 2 letras maiúsculas\n",
    "    df[\"uf\"] = df.get(\"uf\").str.upper()\n",
    "    df[\"municipio\"] = df.get(\"municipio\").str.upper()\n",
    "\n",
    "\n",
    "    # 14) Filtro do DDL: apenas 2024 ou 2025\n",
    "    print(\"6) Aplicando filtro ano_arquivo (2024/2025)...\")\n",
    "    before = len(df)\n",
    "    df = df[df[\"ano_arquivo\"].isin([2024, 2025])].copy()\n",
    "    print(f\"   Linhas removidas pelo filtro: {before - len(df):,}\")\n",
    "\n",
    "    # 15) Ajustar colunas finais (DDL) + criar as que faltam como NULL\n",
    "    print(\"7) Garantindo colunas do DDL...\")\n",
    "    for col in DDL_COLUMNS:\n",
    "        if col not in df.columns:\n",
    "            df[col] = pd.NA\n",
    "\n",
    "    # 16) Remover duplicatas na PK (sinistro_id, pessoa_id)\n",
    "    print(\"8) Removendo duplicatas por (sinistro_id, pessoa_id)...\")\n",
    "    before = len(df)\n",
    "    df = df.sort_values([\"sinistro_id\", \"pessoa_id\", \"data_hora\"], na_position=\"last\")\n",
    "    df = df.drop_duplicates(subset=[\"sinistro_id\", \"pessoa_id\"], keep=\"first\")\n",
    "    print(f\"   Duplicatas removidas: {before - len(df):,}\")\n",
    "\n",
    "    # 17) Selecionar só as colunas do contrato (DDL)\n",
    "    df_silver = df[DDL_COLUMNS].copy()\n",
    "\n",
    "    print(f\"Shape final (silver): {df_silver.shape}\")\n",
    "    return df_silver\n",
    "\n",
    "\n",
    "df_silver = transformar_para_silver(df_raw)\n",
    "df_silver.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f4f0088e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VALIDACOES\n",
      "Ano (value_counts):\n",
      "ano_arquivo\n",
      "2024    189998\n",
      "2025    170009\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Nulos nas chaves:\n",
      "sinistro_id null: 0\n",
      "pessoa_id   null: 0\n",
      "\n",
      "Exemplo de colunas:\n",
      "       sinistro_id  pessoa_id  veiculo_id           data_hora  dia_semana_num  \\\n",
      "41640       571772    1268971     1018215 2024-01-01 00:05:00               0   \n",
      "41641       571774    1268985     1018226 2024-01-01 00:05:00               0   \n",
      "41642       571777    1269020     1018251 2024-01-01 01:45:00               0   \n",
      "41643       571778    1269028     1018261 2024-01-01 00:45:00               0   \n",
      "41644       571778    1269045     1018261 2024-01-01 00:45:00               0   \n",
      "41648       571779    1268976     1018219 2024-01-01 01:45:00               0   \n",
      "41645       571779    1268998     1018219 2024-01-01 01:45:00               0   \n",
      "41646       571779    1268999     1018219 2024-01-01 01:45:00               0   \n",
      "41647       571779    1269000     1018219 2024-01-01 01:45:00               0   \n",
      "41650       571780    1268977     1018220 2024-01-01 01:50:00               0   \n",
      "\n",
      "      sexo_condutor faixa_etaria_condutor  \n",
      "41640     masculino                 20-29  \n",
      "41641      feminino                 30-39  \n",
      "41642     masculino                 50-59  \n",
      "41643     masculino                 50-59  \n",
      "41644      feminino                 30-39  \n",
      "41648     masculino                 40-49  \n",
      "41645      feminino                   0-9  \n",
      "41646     masculino                   0-9  \n",
      "41647      feminino                 10-19  \n",
      "41650     masculino                 40-49  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVALIDACOES\")\n",
    "\n",
    "print(\"Ano (value_counts):\")\n",
    "print(df_silver[\"ano_arquivo\"].value_counts(dropna=False))\n",
    "\n",
    "print(\"\\nNulos nas chaves:\")\n",
    "print(\"sinistro_id null:\", df_silver[\"sinistro_id\"].isna().sum())\n",
    "print(\"pessoa_id   null:\", df_silver[\"pessoa_id\"].isna().sum())\n",
    "\n",
    "print(\"\\nExemplo de colunas:\")\n",
    "print(df_silver[[\"sinistro_id\",\"pessoa_id\",\"veiculo_id\",\"data_hora\",\"dia_semana_num\",\"sexo_condutor\",\"faixa_etaria_condutor\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c2c95ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Silver salvo em: /home/matheus-brant/Desktop/referencia/SBD2-Grupo-19-PRF/data_layer/silver/data/sinistros_silver.csv\n",
      "Tamanho (linhas): 360007\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_FILE = DATA_LAYER_SILVER_PATH / \"sinistros_silver.csv\"\n",
    "\n",
    "df_silver.to_csv(OUTPUT_FILE, index=False, encoding=\"utf-8\")\n",
    "print(\"CSV Silver salvo em:\", OUTPUT_FILE)\n",
    "print(\"Tamanho (linhas):\", len(df_silver))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818e6190",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nQuick checks:\")\n",
    "print(\"latitude null %:\", df_silver[\"latitude\"].isna().mean())\n",
    "print(\"longitude null %:\", df_silver[\"longitude\"].isna().mean())\n",
    "print(\"ano_arquivo null:\", df_silver[\"ano_arquivo\"].isna().sum())\n",
    "print(\"data_hora null:\", df_silver[\"data_hora\"].isna().sum())\n",
    "print(\"municipio sample:\", df_silver[\"municipio\"].dropna().unique()[:5])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
