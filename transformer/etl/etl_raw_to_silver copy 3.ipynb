{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a9b7c88",
   "metadata": {},
   "source": [
    "1. Importações e definições de variáveis de ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b0bd2dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETL RAW -> SILVER | SINISTROS PRF\n",
      "Arquivos encontrados em raw: 2\n",
      " - /home/matheus-brant/Desktop/referencia/SBD2-Grupo-19-PRF/data_layer/raw/dados_brutos_2024.csv\n",
      " - /home/matheus-brant/Desktop/referencia/SBD2-Grupo-19-PRF/data_layer/raw/dados_brutos_2025.csv\n",
      "DB host: localhost\n",
      "DB port: 5432\n",
      "DB name: prf\n"
     ]
    }
   ],
   "source": [
    "# ETL RAW -> SILVER | SINISTROS PRF\n",
    "\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import unicodedata\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", 80)\n",
    "\n",
    "print(\"ETL RAW -> SILVER | SINISTROS PRF\")\n",
    "\n",
    "# Caminhos\n",
    "BASE_PATH = Path(os.getcwd()).parent.parent\n",
    "RAW_PATH = BASE_PATH / \"data_layer\" / \"raw\"\n",
    "SILVER_PATH = BASE_PATH / \"data_layer\" / \"silver\" / \"data\"\n",
    "SILVER_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RAW_FILES = sorted([p for p in RAW_PATH.iterdir() if p.suffix.lower() == \".csv\"])\n",
    "\n",
    "print(f\"Arquivos encontrados em raw: {len(RAW_FILES)}\")\n",
    "for p in RAW_FILES:\n",
    "    print(\" -\", p)\n",
    "\n",
    "# Banco (.env)\n",
    "load_dotenv(BASE_PATH / \".env\")\n",
    "\n",
    "DB_CONFIG = {\n",
    "    \"host\": os.getenv(\"DB_HOST\"),\n",
    "    \"port\": os.getenv(\"DB_PORT\"),\n",
    "    \"database\": os.getenv(\"POSTGRES_DB\"),\n",
    "    \"user\": os.getenv(\"POSTGRES_USER\"),\n",
    "    \"password\": os.getenv(\"POSTGRES_PASSWORD\"),\n",
    "}\n",
    "\n",
    "print(\"DB host:\", DB_CONFIG[\"host\"])\n",
    "print(\"DB port:\", DB_CONFIG[\"port\"])\n",
    "print(\"DB name:\", DB_CONFIG[\"database\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10648602",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd70f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers: normalização e conversões\n",
    "\n",
    "NULL_LIKE = {\"\", \" \", \"null\", \"none\", \"nan\", \"na\", \"n/a\", \"(null)\", \"NoneType\", \"NaN\", \"NULL\", \"N/A\"}\n",
    "\n",
    "VALID_UF = {\n",
    "    \"AC\",\"AL\",\"AP\",\"AM\",\"BA\",\"CE\",\"DF\",\"ES\",\"GO\",\"MA\",\"MT\",\"MS\",\"MG\",\n",
    "    \"PA\",\"PB\",\"PR\",\"PE\",\"PI\",\"RJ\",\"RN\",\"RS\",\"RO\",\"RR\",\"SC\",\"SP\",\"SE\",\"TO\"\n",
    "}\n",
    "\n",
    "UNKNOWN_LIKE = {\n",
    "    \"ignorado\",\n",
    "    \"nao informado\",\n",
    "    \"nao-informado\",\n",
    "    \"sem informacao\",\n",
    "    \"sem-informacao\",\n",
    "    \"desconhecido\",\n",
    "    \"0\",\n",
    "}\n",
    "\n",
    "#Limpa string: trim, espaços duplicados e nulos padrão\n",
    "def normalize_text(s: pd.Series) -> pd.Series:\n",
    "    if s is None:\n",
    "        return pd.Series([], dtype=\"string\")\n",
    "\n",
    "    s = s.astype(\"string\")\n",
    "    s = s.map(lambda x: unicodedata.normalize(\"NFKC\", x) if pd.notna(x) else x)\n",
    "    s = s.str.strip().str.replace(r\"\\s+\", \" \", regex=True)\n",
    "\n",
    "    s_lower = s.str.lower()\n",
    "    return s.mask(s_lower.isin(NULL_LIKE), pd.NA)\n",
    "\n",
    "# Converte para inteiro nullable\n",
    "def to_int(s: pd.Series) -> pd.Series:\n",
    "    return pd.to_numeric(s, errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Converte para float nullable (aceita vírgula)\n",
    "def to_float(s: pd.Series) -> pd.Series:\n",
    "    s = s.astype(\"string\").str.replace(\",\", \".\", regex=False)\n",
    "    return pd.to_numeric(s, errors=\"coerce\").astype(\"Float64\")\n",
    "\n",
    "# Valida faixa de latitude/longitude\n",
    "def validate_coordinates(lat: pd.Series, lon: pd.Series) -> tuple[pd.Series, pd.Series]:\n",
    "    lat = lat.where(lat.isna() | ((lat >= -90) & (lat <= 90)), pd.NA)\n",
    "    lon = lon.where(lon.isna() | ((lon >= -180) & (lon <= 180)), pd.NA)\n",
    "    return lat.astype(\"Float64\"), lon.astype(\"Float64\")\n",
    "\n",
    "# Mantém UF só se for válida\n",
    "def validate_uf(s: pd.Series) -> pd.Series:\n",
    "    s = normalize_text(s).str.upper()\n",
    "    return s.where(s.isin(VALID_UF), pd.NA).astype(\"string\")\n",
    "\n",
    "# Troca valores tipo 'ignorado' por NULL\n",
    "def null_if_unknown(s: pd.Series) -> pd.Series:\n",
    "    s = normalize_text(s)\n",
    "\n",
    "    def _map(x):\n",
    "        if x is None or pd.isna(x):\n",
    "            return pd.NA\n",
    "        v = unicodedata.normalize(\"NFKD\", str(x)).encode(\"ascii\", \"ignore\").decode(\"ascii\").lower().strip()\n",
    "        return pd.NA if v in UNKNOWN_LIKE else x\n",
    "\n",
    "    return s.map(_map).astype(\"string\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e628c107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers: tempo e categorias\n",
    "\n",
    "DAY_MAP = {\n",
    "    \"segunda-feira\": 0,\n",
    "    \"terca-feira\": 1,\n",
    "    \"terça-feira\": 1,\n",
    "    \"quarta-feira\": 2,\n",
    "    \"quinta-feira\": 3,\n",
    "    \"sexta-feira\": 4,\n",
    "    \"sabado\": 5,\n",
    "    \"sábado\": 5,\n",
    "    \"domingo\": 6,\n",
    "}\n",
    "\n",
    "# Aceita HH:MM:SS e HH:MM\n",
    "def parse_time(s: pd.Series) -> pd.Series:\n",
    "    s = normalize_text(s)\n",
    "    t1 = pd.to_datetime(s, format=\"%H:%M:%S\", errors=\"coerce\")\n",
    "    t2 = pd.to_datetime(s, format=\"%H:%M\", errors=\"coerce\")\n",
    "    return t1.fillna(t2).dt.time\n",
    "\n",
    "# Dia da semana -> número (Seg=0 ... Dom=6)\n",
    "def map_weekday(s: pd.Series) -> pd.Series:\n",
    "    def _norm(x):\n",
    "        if x is None or pd.isna(x):\n",
    "            return None\n",
    "        x = unicodedata.normalize(\"NFKD\", str(x)).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "        return x.strip().lower()\n",
    "\n",
    "    s = normalize_text(s).map(_norm)\n",
    "    return s.map(DAY_MAP).astype(\"Int64\")\n",
    "\n",
    "# Sexo -> masculino | feminino | NULL\n",
    "def map_gender(s: pd.Series) -> pd.Series:\n",
    "    s = normalize_text(s)\n",
    "\n",
    "    def _map(x):\n",
    "        if x is None or pd.isna(x):\n",
    "            return pd.NA\n",
    "        v = unicodedata.normalize(\"NFKD\", str(x)).encode(\"ascii\", \"ignore\").decode(\"ascii\").lower().strip()\n",
    "        if v in {\"m\", \"masc\", \"masculino\"}:\n",
    "            return \"masculino\"\n",
    "        if v in {\"f\", \"fem\", \"feminino\"}:\n",
    "            return \"feminino\"\n",
    "        return pd.NA\n",
    "\n",
    "    return s.map(_map).astype(\"string\")\n",
    "\n",
    "#Estado físico -> ileso | leve | grave | obito | NULL\n",
    "def map_physical_state(s: pd.Series) -> pd.Series:\n",
    "    s = normalize_text(s)\n",
    "\n",
    "    def _map(x):\n",
    "        if x is None or pd.isna(x):\n",
    "            return pd.NA\n",
    "        v = unicodedata.normalize(\"NFKD\", str(x)).encode(\"ascii\", \"ignore\").decode(\"ascii\").lower().strip()\n",
    "\n",
    "        if \"obito\" in v or \"morto\" in v:\n",
    "            return \"obito\"\n",
    "        if \"grave\" in v:\n",
    "            return \"grave\"\n",
    "        if \"leve\" in v:\n",
    "            return \"leve\"\n",
    "        if \"ileso\" in v or \"sem ferimentos\" in v:\n",
    "            return \"ileso\"\n",
    "        return pd.NA\n",
    "\n",
    "    return s.map(_map).astype(\"string\")\n",
    "\n",
    "# uso_solo: sim -> urbano | nao -> rural\n",
    "def map_land_use(s: pd.Series) -> pd.Series:\n",
    "    s = normalize_text(s)\n",
    "\n",
    "    def _map(x):\n",
    "        if x is None or pd.isna(x):\n",
    "            return pd.NA\n",
    "        v = unicodedata.normalize(\"NFKD\", str(x)).encode(\"ascii\", \"ignore\").decode(\"ascii\").lower().strip()\n",
    "        if v == \"sim\":\n",
    "            return \"urbano\"\n",
    "        if v == \"nao\":\n",
    "            return \"rural\"\n",
    "        return pd.NA\n",
    "\n",
    "    return s.map(_map).astype(\"string\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e63ff0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers: features derivadas\n",
    "\n",
    "# Idade -> faixas.\n",
    "def age_bucket(age_s: pd.Series) -> pd.Series:\n",
    "    age = pd.to_numeric(age_s, errors=\"coerce\")\n",
    "    age = age.mask((age <= 0) | (age > 120), np.nan)\n",
    "\n",
    "    bins = [-0.1, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99, 10_000]\n",
    "    labels = [\"0-9\",\"10-19\",\"20-29\",\"30-39\",\"40-49\",\"50-59\",\"60-69\",\"70-79\",\"80-89\",\"90-99\",\"100+\"]\n",
    "\n",
    "    return pd.cut(age, bins=bins, labels=labels).astype(\"string\")\n",
    "\n",
    "# Ano fabricação -> idade do veículo -> faixas\n",
    "def vehicle_age_bucket(year_fab_s: pd.Series, year_ref_s: pd.Series) -> pd.Series:\n",
    "    year_fab = pd.to_numeric(year_fab_s, errors=\"coerce\")\n",
    "    year_ref = pd.to_numeric(year_ref_s, errors=\"coerce\")\n",
    "\n",
    "    age = (year_ref - year_fab).mask(lambda x: (x < 0) | (x > 120), np.nan)\n",
    "\n",
    "    bins = [-0.1, 4, 9, 14, 19, 29, 120]\n",
    "    labels = [\"0-4\",\"5-9\",\"10-14\",\"15-19\",\"20-29\",\"30+\"]\n",
    "\n",
    "    return pd.cut(age, bins=bins, labels=labels).astype(\"string\")\n",
    "\n",
    "# Padroniza 'tracado_via' (remove duplicatas e melhora leitura).\n",
    "def standardize_road_layout(s: pd.Series) -> pd.Series:\n",
    "    s = normalize_text(s)\n",
    "    stopwords = {\"de\", \"da\", \"do\", \"das\", \"dos\", \"e\"}\n",
    "\n",
    "    def _key(txt: str) -> str:\n",
    "        return unicodedata.normalize(\"NFKD\", txt).encode(\"ascii\", \"ignore\").decode(\"ascii\").lower().strip()\n",
    "\n",
    "    def _pretty(txt: str) -> str:\n",
    "        words = [w.strip() for w in txt.split() if w.strip()]\n",
    "        out = []\n",
    "        for i, w in enumerate(words):\n",
    "            lw = w.lower()\n",
    "            out.append(lw if (i > 0 and lw in stopwords) else (w[:1].upper() + w[1:].lower()))\n",
    "        return \" \".join(out)\n",
    "\n",
    "    def _map(x):\n",
    "        if x is None or pd.isna(x):\n",
    "            return pd.NA\n",
    "\n",
    "        parts = [p.strip() for p in str(x).split(\";\") if p and p.strip()]\n",
    "        if not parts:\n",
    "            return pd.NA\n",
    "\n",
    "        uniq = {}\n",
    "        for p in parts:\n",
    "            k = _key(p)\n",
    "            if k and k not in uniq:\n",
    "                uniq[k] = _pretty(p)\n",
    "\n",
    "        ordered = [uniq[k] for k in sorted(uniq.keys())]\n",
    "        return \";\".join(ordered) if ordered else pd.NA\n",
    "\n",
    "    return s.map(_map).astype(\"string\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5a03cdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD: funções de banco\n",
    "def get_conn(db_config: dict):\n",
    "    return psycopg2.connect(\n",
    "        host=db_config[\"host\"],\n",
    "        port=db_config[\"port\"],\n",
    "        dbname=db_config[\"database\"],\n",
    "        user=db_config[\"user\"],\n",
    "        password=db_config[\"password\"],\n",
    "    )\n",
    "\n",
    "def load_to_postgres(df: pd.DataFrame, db_config: dict, mode: str = \"truncate\"):\n",
    "    cols = [\n",
    "        \"ano_arquivo\",\"sinistro_id\",\"pessoa_id\",\"veiculo_id\",\"data_hora\",\"dia_semana_num\",\n",
    "        \"uf\",\"municipio\",\"delegacia\",\"latitude\",\"longitude\",\"causa_acidente\",\"tipo_acidente\",\n",
    "        \"classificacao_acidente\",\"fase_dia\",\"sentido_via\",\"condicao_meteorologica\",\"tipo_pista\",\n",
    "        \"tracado_via\",\"caracteristicas_via\",\"tipo_envolvido\",\"estado_fisico\",\"faixa_etaria_condutor\",\n",
    "        \"sexo_condutor\",\"tipo_veiculo\",\"faixa_idade_veiculo\",\n",
    "    ]\n",
    "\n",
    "    df_load = df[cols].copy()\n",
    "    df_load = df_load[cols].copy()\n",
    "\n",
    "    # troca tudo que é \"missing\" do pandas por None\n",
    "    df_load = df_load.astype(object).where(pd.notna(df_load), None)\n",
    "\n",
    "    records = [tuple(row) for row in df_load.itertuples(index=False, name=None)]\n",
    "\n",
    "\n",
    "    if not records:\n",
    "        print(\"Nada para carregar (df vazio).\")\n",
    "        return\n",
    "\n",
    "    if mode == \"upsert\":\n",
    "        set_cols = [c for c in cols if c not in (\"sinistro_id\", \"pessoa_id\")]\n",
    "        set_clause = \", \".join([f\"{c}=EXCLUDED.{c}\" for c in set_cols])\n",
    "        insert_sql = f\"\"\"\n",
    "            INSERT INTO silver.sinistros ({\",\".join(cols)})\n",
    "            VALUES %s\n",
    "            ON CONFLICT (sinistro_id, pessoa_id)\n",
    "            DO UPDATE SET {set_clause}\n",
    "        \"\"\"\n",
    "    else:\n",
    "        insert_sql = f\"\"\"\n",
    "            INSERT INTO silver.sinistros ({\",\".join(cols)})\n",
    "            VALUES %s\n",
    "        \"\"\"\n",
    "\n",
    "    conn = get_conn(db_config)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        cur.execute(\"SELECT 1;\")\n",
    "\n",
    "        if mode == \"truncate\":\n",
    "            cur.execute(\"TRUNCATE TABLE silver.sinistros;\")\n",
    "            conn.commit()\n",
    "\n",
    "        execute_values(cur, insert_sql, records, page_size=5000)\n",
    "        conn.commit()\n",
    "\n",
    "        print(f\"Load OK: {len(records):,} linhas processadas (mode={mode})\")\n",
    "\n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "877943a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Carregando dados Raw...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregado: 372,148 linhas x 36 colunas\n",
      "Colunas: ['id', 'pesid', 'data_inversa', 'dia_semana', 'horario', 'uf', 'br', 'km', 'municipio', 'causa_acidente', 'tipo_acidente', 'classificacao_acidente', 'fase_dia', 'sentido_via', 'condicao_metereologica', 'tipo_pista', 'tracado_via', 'uso_solo', 'id_veiculo', 'tipo_veiculo', 'marca', 'ano_fabricacao_veiculo', 'tipo_envolvido', 'estado_fisico', 'idade', 'sexo', 'ilesos', 'feridos_leves', 'feridos_graves', 'mortos', 'latitude', 'longitude', 'regional', 'delegacia', 'uop', '__source_file']\n"
     ]
    }
   ],
   "source": [
    "# Carrega e junta os CSVs raw\n",
    "\n",
    "def load_raw_csvs(csv_paths: list[Path]) -> pd.DataFrame:\n",
    "    dfs = []\n",
    "    for p in csv_paths:\n",
    "        df = pd.read_csv(\n",
    "            p,\n",
    "            sep=\";\",\n",
    "            encoding=\"ISO-8859-1\",\n",
    "            low_memory=False,\n",
    "            dtype=str,\n",
    "        )\n",
    "        df[\"__source_file\"] = p.name\n",
    "        dfs.append(df)\n",
    "\n",
    "    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
    "\n",
    "print(\"\\nCarregando dados Raw...\")\n",
    "df_raw = load_raw_csvs(RAW_FILES)\n",
    "\n",
    "print(f\"Carregado: {df_raw.shape[0]:,} linhas x {df_raw.shape[1]:,} colunas\")\n",
    "print(\"Colunas:\", list(df_raw.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2f2ad581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INICIANDO TRANSFORM (RAW -> SILVER)\n",
      "Shape inicial: (372148, 36)\n",
      "Normalizando texto...\n",
      "Convertendo IDs...\n",
      "Convertendo data e horário...\n",
      "Criando data_hora...\n",
      "Convertendo latitude/longitude...\n",
      "Aplicando filtro ano_arquivo (2024/2025)...\n",
      "   Linhas removidas pelo filtro: 0\n",
      "Garantindo colunas do contrato...\n",
      "   Linhas removidas por PK inválida: 32,967\n",
      "Removendo duplicatas por (sinistro_id, pessoa_id)...\n",
      "   Duplicatas removidas: 0\n",
      "Shape final (silver): (339181, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano_arquivo</th>\n",
       "      <th>sinistro_id</th>\n",
       "      <th>pessoa_id</th>\n",
       "      <th>veiculo_id</th>\n",
       "      <th>data_hora</th>\n",
       "      <th>dia_semana_num</th>\n",
       "      <th>uf</th>\n",
       "      <th>municipio</th>\n",
       "      <th>delegacia</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>causa_acidente</th>\n",
       "      <th>tipo_acidente</th>\n",
       "      <th>classificacao_acidente</th>\n",
       "      <th>fase_dia</th>\n",
       "      <th>sentido_via</th>\n",
       "      <th>condicao_meteorologica</th>\n",
       "      <th>tipo_pista</th>\n",
       "      <th>tracado_via</th>\n",
       "      <th>caracteristicas_via</th>\n",
       "      <th>tipo_envolvido</th>\n",
       "      <th>estado_fisico</th>\n",
       "      <th>faixa_etaria_condutor</th>\n",
       "      <th>sexo_condutor</th>\n",
       "      <th>tipo_veiculo</th>\n",
       "      <th>faixa_idade_veiculo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41640</th>\n",
       "      <td>2024</td>\n",
       "      <td>571772</td>\n",
       "      <td>1268971</td>\n",
       "      <td>1018215</td>\n",
       "      <td>2024-01-01 00:05:00</td>\n",
       "      <td>0</td>\n",
       "      <td>RJ</td>\n",
       "      <td>TANGUA</td>\n",
       "      <td>DEL02-RJ</td>\n",
       "      <td>-22.72936</td>\n",
       "      <td>-42.701125</td>\n",
       "      <td>Reação tardia ou ineficiente do condutor</td>\n",
       "      <td>Colisão com objeto</td>\n",
       "      <td>Com Vítimas Fatais</td>\n",
       "      <td>Plena Noite</td>\n",
       "      <td>Decrescente</td>\n",
       "      <td>Céu Claro</td>\n",
       "      <td>Dupla</td>\n",
       "      <td>Reta</td>\n",
       "      <td>urbano</td>\n",
       "      <td>Condutor</td>\n",
       "      <td>obito</td>\n",
       "      <td>20-29</td>\n",
       "      <td>masculino</td>\n",
       "      <td>Motocicleta</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41641</th>\n",
       "      <td>2024</td>\n",
       "      <td>571774</td>\n",
       "      <td>1268985</td>\n",
       "      <td>1018226</td>\n",
       "      <td>2024-01-01 00:05:00</td>\n",
       "      <td>0</td>\n",
       "      <td>GO</td>\n",
       "      <td>ANAPOLIS</td>\n",
       "      <td>DEL02-GO</td>\n",
       "      <td>-16.229185</td>\n",
       "      <td>-49.009797</td>\n",
       "      <td>Velocidade Incompatível</td>\n",
       "      <td>Colisão com objeto</td>\n",
       "      <td>Sem Vítimas</td>\n",
       "      <td>Plena Noite</td>\n",
       "      <td>Decrescente</td>\n",
       "      <td>Céu Claro</td>\n",
       "      <td>Dupla</td>\n",
       "      <td>Reta</td>\n",
       "      <td>rural</td>\n",
       "      <td>Condutor</td>\n",
       "      <td>ileso</td>\n",
       "      <td>30-39</td>\n",
       "      <td>feminino</td>\n",
       "      <td>Automóvel</td>\n",
       "      <td>15-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41642</th>\n",
       "      <td>2024</td>\n",
       "      <td>571777</td>\n",
       "      <td>1269020</td>\n",
       "      <td>1018251</td>\n",
       "      <td>2024-01-01 01:45:00</td>\n",
       "      <td>0</td>\n",
       "      <td>ES</td>\n",
       "      <td>SERRA</td>\n",
       "      <td>DEL02-ES</td>\n",
       "      <td>-20.172928</td>\n",
       "      <td>-40.267364</td>\n",
       "      <td>Reação tardia ou ineficiente do condutor</td>\n",
       "      <td>Colisão com objeto</td>\n",
       "      <td>Sem Vítimas</td>\n",
       "      <td>Plena Noite</td>\n",
       "      <td>Decrescente</td>\n",
       "      <td>Nublado</td>\n",
       "      <td>Múltipla</td>\n",
       "      <td>Interseção de Vias;Reta</td>\n",
       "      <td>urbano</td>\n",
       "      <td>Condutor</td>\n",
       "      <td>ileso</td>\n",
       "      <td>50-59</td>\n",
       "      <td>masculino</td>\n",
       "      <td>Caminhonete</td>\n",
       "      <td>15-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41643</th>\n",
       "      <td>2024</td>\n",
       "      <td>571778</td>\n",
       "      <td>1269028</td>\n",
       "      <td>1018261</td>\n",
       "      <td>2024-01-01 00:45:00</td>\n",
       "      <td>0</td>\n",
       "      <td>SC</td>\n",
       "      <td>PENHA</td>\n",
       "      <td>DEL03-SC</td>\n",
       "      <td>-26.83477</td>\n",
       "      <td>-48.706151</td>\n",
       "      <td>Acumulo de água sobre o pavimento</td>\n",
       "      <td>Saída de leito carroçável</td>\n",
       "      <td>Com Vítimas Feridas</td>\n",
       "      <td>Plena Noite</td>\n",
       "      <td>Crescente</td>\n",
       "      <td>Chuva</td>\n",
       "      <td>Dupla</td>\n",
       "      <td>Curva</td>\n",
       "      <td>rural</td>\n",
       "      <td>Condutor</td>\n",
       "      <td>ileso</td>\n",
       "      <td>50-59</td>\n",
       "      <td>masculino</td>\n",
       "      <td>Camioneta</td>\n",
       "      <td>10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41644</th>\n",
       "      <td>2024</td>\n",
       "      <td>571778</td>\n",
       "      <td>1269045</td>\n",
       "      <td>1018261</td>\n",
       "      <td>2024-01-01 00:45:00</td>\n",
       "      <td>0</td>\n",
       "      <td>SC</td>\n",
       "      <td>PENHA</td>\n",
       "      <td>DEL03-SC</td>\n",
       "      <td>-26.83477</td>\n",
       "      <td>-48.706151</td>\n",
       "      <td>Acumulo de água sobre o pavimento</td>\n",
       "      <td>Saída de leito carroçável</td>\n",
       "      <td>Com Vítimas Feridas</td>\n",
       "      <td>Plena Noite</td>\n",
       "      <td>Crescente</td>\n",
       "      <td>Chuva</td>\n",
       "      <td>Dupla</td>\n",
       "      <td>Curva</td>\n",
       "      <td>rural</td>\n",
       "      <td>Passageiro</td>\n",
       "      <td>leve</td>\n",
       "      <td>30-39</td>\n",
       "      <td>feminino</td>\n",
       "      <td>Camioneta</td>\n",
       "      <td>10-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ano_arquivo  sinistro_id  pessoa_id  veiculo_id           data_hora  \\\n",
       "41640         2024       571772    1268971     1018215 2024-01-01 00:05:00   \n",
       "41641         2024       571774    1268985     1018226 2024-01-01 00:05:00   \n",
       "41642         2024       571777    1269020     1018251 2024-01-01 01:45:00   \n",
       "41643         2024       571778    1269028     1018261 2024-01-01 00:45:00   \n",
       "41644         2024       571778    1269045     1018261 2024-01-01 00:45:00   \n",
       "\n",
       "       dia_semana_num  uf municipio delegacia   latitude  longitude  \\\n",
       "41640               0  RJ    TANGUA  DEL02-RJ  -22.72936 -42.701125   \n",
       "41641               0  GO  ANAPOLIS  DEL02-GO -16.229185 -49.009797   \n",
       "41642               0  ES     SERRA  DEL02-ES -20.172928 -40.267364   \n",
       "41643               0  SC     PENHA  DEL03-SC  -26.83477 -48.706151   \n",
       "41644               0  SC     PENHA  DEL03-SC  -26.83477 -48.706151   \n",
       "\n",
       "                                 causa_acidente              tipo_acidente  \\\n",
       "41640  Reação tardia ou ineficiente do condutor         Colisão com objeto   \n",
       "41641                   Velocidade Incompatível         Colisão com objeto   \n",
       "41642  Reação tardia ou ineficiente do condutor         Colisão com objeto   \n",
       "41643         Acumulo de água sobre o pavimento  Saída de leito carroçável   \n",
       "41644         Acumulo de água sobre o pavimento  Saída de leito carroçável   \n",
       "\n",
       "      classificacao_acidente     fase_dia  sentido_via condicao_meteorologica  \\\n",
       "41640     Com Vítimas Fatais  Plena Noite  Decrescente              Céu Claro   \n",
       "41641            Sem Vítimas  Plena Noite  Decrescente              Céu Claro   \n",
       "41642            Sem Vítimas  Plena Noite  Decrescente                Nublado   \n",
       "41643    Com Vítimas Feridas  Plena Noite    Crescente                  Chuva   \n",
       "41644    Com Vítimas Feridas  Plena Noite    Crescente                  Chuva   \n",
       "\n",
       "      tipo_pista              tracado_via caracteristicas_via tipo_envolvido  \\\n",
       "41640      Dupla                     Reta              urbano       Condutor   \n",
       "41641      Dupla                     Reta               rural       Condutor   \n",
       "41642   Múltipla  Interseção de Vias;Reta              urbano       Condutor   \n",
       "41643      Dupla                    Curva               rural       Condutor   \n",
       "41644      Dupla                    Curva               rural     Passageiro   \n",
       "\n",
       "      estado_fisico faixa_etaria_condutor sexo_condutor tipo_veiculo  \\\n",
       "41640         obito                 20-29     masculino  Motocicleta   \n",
       "41641         ileso                 30-39      feminino    Automóvel   \n",
       "41642         ileso                 50-59     masculino  Caminhonete   \n",
       "41643         ileso                 50-59     masculino    Camioneta   \n",
       "41644          leve                 30-39      feminino    Camioneta   \n",
       "\n",
       "      faixa_idade_veiculo  \n",
       "41640                 0-4  \n",
       "41641               15-19  \n",
       "41642               15-19  \n",
       "41643               10-14  \n",
       "41644               10-14  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SILVER_COLUMNS = [\n",
    "    \"ano_arquivo\",\n",
    "    \"sinistro_id\",\n",
    "    \"pessoa_id\",\n",
    "    \"veiculo_id\",\n",
    "    \"data_hora\",\n",
    "    \"dia_semana_num\",\n",
    "    \"uf\",\n",
    "    \"municipio\",\n",
    "    \"delegacia\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"causa_acidente\",\n",
    "    \"tipo_acidente\",\n",
    "    \"classificacao_acidente\",\n",
    "    \"fase_dia\",\n",
    "    \"sentido_via\",\n",
    "    \"condicao_meteorologica\",\n",
    "    \"tipo_pista\",\n",
    "    \"tracado_via\",\n",
    "    \"caracteristicas_via\",\n",
    "    \"tipo_envolvido\",\n",
    "    \"estado_fisico\",\n",
    "    \"faixa_etaria_condutor\",\n",
    "    \"sexo_condutor\",\n",
    "    \"tipo_veiculo\",\n",
    "    \"faixa_idade_veiculo\",\n",
    "]\n",
    "\n",
    "def to_silver(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    print(\"\\nINICIANDO TRANSFORM (RAW -> SILVER)\")\n",
    "    print(f\"Shape inicial: {df.shape}\")\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Normalização geral\n",
    "    print(\"Normalizando texto...\")\n",
    "    for col in df.columns:\n",
    "        df[col] = normalize_text(df[col])\n",
    "\n",
    "    # Corrigir typo de coluna\n",
    "    if \"condicao_metereologica\" in df.columns:\n",
    "        df = df.rename(columns={\"condicao_metereologica\": \"condicao_meteorologica\"})\n",
    "\n",
    "    df[\"condicao_meteorologica\"] = null_if_unknown(df.get(\"condicao_meteorologica\"))\n",
    "\n",
    "    # IDs\n",
    "    print(\"Convertendo IDs...\")\n",
    "    df[\"sinistro_id\"] = to_int(df[\"id\"]) if \"id\" in df.columns else pd.NA\n",
    "    df[\"pessoa_id\"] = to_int(df[\"pesid\"]) if \"pesid\" in df.columns else pd.NA\n",
    "    df[\"veiculo_id\"] = to_int(df[\"id_veiculo\"]) if \"id_veiculo\" in df.columns else pd.NA\n",
    "    df[\"sinistro_id\"] = df[\"sinistro_id\"].where(df[\"sinistro_id\"].isna() | (df[\"sinistro_id\"] > 0), pd.NA)\n",
    "    df[\"pessoa_id\"]   = df[\"pessoa_id\"].where(df[\"pessoa_id\"].isna() | (df[\"pessoa_id\"] > 0), pd.NA)\n",
    "    df[\"veiculo_id\"]  = df[\"veiculo_id\"].where(df[\"veiculo_id\"].isna() | (df[\"veiculo_id\"] > 0), pd.NA)\n",
    "\n",
    "\n",
    "    # Data/hora\n",
    "    print(\"Convertendo data e horário...\")\n",
    "    df[\"date_dt\"] = pd.to_datetime(df.get(\"data_inversa\"), format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "    df[\"time_dt\"] = parse_time(df.get(\"horario\"))\n",
    "\n",
    "    print(\"Criando data_hora...\")\n",
    "    time_txt = df[\"time_dt\"].astype(\"string\").fillna(\"00:00:00\")\n",
    "    df[\"data_hora\"] = pd.to_datetime(df[\"date_dt\"].astype(\"string\") + \" \" + time_txt, errors=\"coerce\")\n",
    "\n",
    "    df[\"ano_arquivo\"] = df[\"data_hora\"].dt.year.astype(\"Int64\")\n",
    "    df[\"dia_semana_num\"] = map_weekday(df.get(\"dia_semana\"))\n",
    "\n",
    "    # Coordenadas\n",
    "    print(\"Convertendo latitude/longitude...\")\n",
    "    df[\"latitude\"] = to_float(df.get(\"latitude\"))\n",
    "    df[\"longitude\"] = to_float(df.get(\"longitude\"))\n",
    "    df[\"latitude\"], df[\"longitude\"] = validate_coordinates(df[\"latitude\"], df[\"longitude\"])\n",
    "\n",
    "    # Campos derivados\n",
    "    df[\"caracteristicas_via\"] = map_land_use(df.get(\"uso_solo\"))\n",
    "    df[\"sexo_condutor\"] = map_gender(df.get(\"sexo\"))\n",
    "    df[\"estado_fisico\"] = map_physical_state(df.get(\"estado_fisico\"))\n",
    "    df[\"faixa_etaria_condutor\"] = age_bucket(df.get(\"idade\"))\n",
    "    df[\"tracado_via\"] = standardize_road_layout(df.get(\"tracado_via\"))\n",
    "    df[\"faixa_idade_veiculo\"] = vehicle_age_bucket(df.get(\"ano_fabricacao_veiculo\"), df[\"ano_arquivo\"])\n",
    "\n",
    "    # UF + município\n",
    "    df[\"uf\"] = validate_uf(df.get(\"uf\"))\n",
    "    df[\"municipio\"] = df.get(\"municipio\").str.upper()\n",
    "\n",
    "    # Filtro de ano\n",
    "    print(\"Aplicando filtro ano_arquivo (2024/2025)...\")\n",
    "    before = len(df)\n",
    "    df = df[df[\"ano_arquivo\"].isin([2024, 2025])].copy()\n",
    "    print(f\"   Linhas removidas pelo filtro: {before - len(df):,}\")\n",
    "\n",
    "    # Garantir colunas finais\n",
    "    print(\"Garantindo colunas do contrato...\")\n",
    "    for col in SILVER_COLUMNS:\n",
    "        if col not in df.columns:\n",
    "            df[col] = pd.NA\n",
    "    \n",
    "    before_pk = len(df)\n",
    "    df = df[df[\"sinistro_id\"].notna() & df[\"pessoa_id\"].notna()].copy()\n",
    "    print(f\"   Linhas removidas por PK inválida: {before_pk - len(df):,}\")\n",
    "\n",
    "\n",
    "    # Deduplicação por PK\n",
    "    print(\"Removendo duplicatas por (sinistro_id, pessoa_id)...\")\n",
    "    before = len(df)\n",
    "    df[\"__completeness\"] = df[SILVER_COLUMNS].notna().sum(axis=1)\n",
    "\n",
    "    df = df.sort_values(\n",
    "        [\"sinistro_id\", \"pessoa_id\", \"__completeness\", \"data_hora\"],\n",
    "        ascending=[True, True, False, False],\n",
    "        na_position=\"last\",\n",
    "    )\n",
    "\n",
    "    df = df.drop_duplicates(subset=[\"sinistro_id\", \"pessoa_id\"], keep=\"first\").drop(columns=\"__completeness\")\n",
    "    print(f\"   Duplicatas removidas: {before - len(df):,}\")\n",
    "\n",
    "    df_silver = df[SILVER_COLUMNS].copy()\n",
    "    print(f\"Shape final (silver): {df_silver.shape}\")\n",
    "    return df_silver\n",
    "\n",
    "df_silver = to_silver(df_raw)\n",
    "df_silver.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5c542ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VALIDAÇÕES\n",
      "Ano (value_counts):\n",
      "ano_arquivo\n",
      "2024    179114\n",
      "2025    160067\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Nulos nas chaves:\n",
      "sinistro_id null: 0\n",
      "pessoa_id   null: 0\n",
      "\n",
      "'ignorado' em condicao_meteorologica (ideal = 0):\n",
      "0\n",
      "\n",
      "CSV Silver salvo em: /home/matheus-brant/Desktop/referencia/SBD2-Grupo-19-PRF/data_layer/silver/data/sinistros_silver.csv\n",
      "Tamanho (linhas): 339181\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVALIDAÇÕES\")\n",
    "\n",
    "print(\"Ano (value_counts):\")\n",
    "print(df_silver[\"ano_arquivo\"].value_counts(dropna=False))\n",
    "\n",
    "print(\"\\nNulos nas chaves:\")\n",
    "print(\"sinistro_id null:\", df_silver[\"sinistro_id\"].isna().sum())\n",
    "print(\"pessoa_id   null:\", df_silver[\"pessoa_id\"].isna().sum())\n",
    "\n",
    "print(\"\\n'ignorado' em condicao_meteorologica (ideal = 0):\")\n",
    "print((df_silver[\"condicao_meteorologica\"].astype(\"string\").str.lower() == \"ignorado\").sum())\n",
    "\n",
    "OUTPUT_FILE = SILVER_PATH / \"sinistros_silver.csv\"\n",
    "df_silver.to_csv(OUTPUT_FILE, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"\\nCSV Silver salvo em:\", OUTPUT_FILE)\n",
    "print(\"Tamanho (linhas):\", len(df_silver))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7023d47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CARREGANDO NO POSTGRES (silver.sinistros)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load OK: 339,181 linhas processadas (mode=truncate)\n",
      "Total no banco: 339,181\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCARREGANDO NO POSTGRES (silver.sinistros)...\")\n",
    "\n",
    "\n",
    "# Mode:\"truncate\" = limpa e recarrega tudo, \"upsert\"   = insere/atualiza se repetir PK\n",
    "load_to_postgres(df_silver, DB_CONFIG, mode=\"truncate\")\n",
    "\n",
    "# valida no banco\n",
    "conn = get_conn(DB_CONFIG)\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT COUNT(*) FROM silver.sinistros;\")\n",
    "total = cur.fetchone()[0]\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "print(f\"Total no banco: {total:,}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
